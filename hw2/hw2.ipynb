{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    " Name | F1 | F2 | Output|\n",
    " | - | - | - | -|\n",
    "  Ex1 | b | b  | +|\n",
    "  Ex2 | c | b |  +|\n",
    "  Ex3 | b|  c  | +|\n",
    "  Ex4 | a | b  | -|\n",
    "  Ex5 | c | a |  -|\n",
    "\n",
    "\n",
    "1. What score would the information gain calculation assign to each of the features?  Be sure to show all your work.\n",
    "\n",
    "Solution: \n",
    "\n",
    "$IG(F1) = \\frac{2}{5}\\cdot 0 + \\frac{2}{5} \\cdot 1 + \\frac{1}{5} \\cdot 0 = 0.4$\n",
    "\n",
    "$IG(F2) = \\frac{3}{5} \\cdot I(\\frac{2}{3}, \\frac{1}{3}) + \\frac{1}{5} \\cdot 0 + \\frac{1}{5} \\cdot 0 \\approx 0.92 \\cdot 0.6 = .552$\n",
    "\n",
    "2. What would be the recursive calls be (show the specific arguments; use the examplesâ€™ names for simplicity)?\n",
    "\n",
    "Solution:\n",
    "\n",
    "First, split into 3 groups based on $F1$:\n",
    "\n",
    "Group 1 - {Ex1, Ex3} (Base Case)\n",
    "\n",
    "Group 2 - {Ex2, Ex5} (Split again based on $F2$, that takes us to base case for those two nodes)\n",
    "\n",
    "Group 3 - {Ex4} (Base Case)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182958340544896"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# calculation for I(2/3, 1/3)\n",
    "-(np.log2(2/3)*(2/3) + np.log2(1/3)*(1/3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree ID3/C4.5 Algorithm (Alpaydin Fig 9.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "x = Counter(np.array([1, 1, 2, 3]))\n",
    "x.get(5, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 1, 3], dtype='int64')\n",
      "Int64Index([2, 5], dtype='int64')\n",
      "Int64Index([4], dtype='int64')\n",
      "Int64Index([6], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'a': [1,1,2,1,3,2,4], 'b': [1,1,1,1,1,1,1]})\n",
    "for _, group in df.groupby('a'):\n",
    "    print(group.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2])[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, feature_idx=None):\n",
    "        self.mapping = {}\n",
    "        self.is_categorical = None\n",
    "        self.feature_idx = feature_idx\n",
    "        self.numeric_split = None\n",
    "        self.prediction = None\n",
    "\n",
    "    def predict(self, example: np.array):\n",
    "        if self.prediction is not None:\n",
    "            return self.prediction\n",
    "        if self.is_categorical:\n",
    "            try:\n",
    "                return self.mapping[example[self.feature_idx]]\n",
    "            except:\n",
    "                print('missing value during evaluation')\n",
    "                return np.random.choice(list(self.mapping.values()))\n",
    "        # feature is numeric\n",
    "        if example[self.feature_idx] <= self.numeric_split:\n",
    "            return self.mapping['left']\n",
    "        return self.mapping['right']\n",
    "\n",
    "\n",
    "    def __str__(self, level=0):\n",
    "        if self.mapping == {}:\n",
    "            return repr(self)\n",
    "        ret = \"\\t\"*level+f'{repr(self)}\\n'\n",
    "        for feature, child in self.mapping.items():\n",
    "            ret += (\"\\t\"*(level + 1) + f\"value {feature} ---\" + child.__str__(level+1) + '\\n')\n",
    "        return ret\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'feature idx: {self.feature_idx} is_categorical: {self.is_categorical} numeric_split: {self.numeric_split} prediction: {self.prediction}'\n",
    "\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, theta_i=0.5, num_classes=None):\n",
    "        self.theta_i = theta_i\n",
    "        self.tree = None\n",
    "        self.num_classes = num_classes\n",
    "        self.cat_feature_idx = None\n",
    "        self.count = 0\n",
    "\n",
    "    def get_class_counts(self, y: np.array):\n",
    "        assert len(y.shape) == 1 # y must be a 1-d array of outputs 0 ... self.num_classes\n",
    "        assert self.num_classes is not None\n",
    "        counts = np.zeros(self.num_classes)\n",
    "        for element in y:\n",
    "            counts[element] += 1\n",
    "        \n",
    "        return counts\n",
    "\n",
    "\n",
    "    def node_entropy(self, y: np.array): # note that the maximum entropy should be -log2(1/num_classes), not necessarily 1\n",
    "        counts = self.get_class_counts(y)\n",
    "        norm_counts = counts / len(y)\n",
    "        unsummed_entropy = norm_counts * np.log2(norm_counts)\n",
    "        unsummed_entropy = np.nan_to_num(unsummed_entropy)\n",
    "        return - np.sum(unsummed_entropy)\n",
    "\n",
    "\n",
    "    def split_entropy(self, branches: List[List], y: np.array):\n",
    "        entropy = 0\n",
    "        # print(branches, y)\n",
    "        for branch in branches:\n",
    "            entropy += self.node_entropy(y[branch]) * len(branch) / len(y)\n",
    "        return entropy\n",
    "\n",
    "\n",
    "    def split_categorical_feature(self, X_feat: np.array, y: np.array):\n",
    "        feat_df = pd.DataFrame({'X_feat': X_feat, 'y': y})\n",
    "        group_indices = {}\n",
    "        for group_name, group in feat_df.groupby('X_feat'):\n",
    "            group_indices[group_name] = group.index.to_numpy()\n",
    "        return group_indices\n",
    "\n",
    "\n",
    "    def split_attribute(self, X: np.array, y: np.array):\n",
    "        min_entropy = np.inf\n",
    "        best_f = None\n",
    "        is_categorical = False\n",
    "        for i in range(X.shape[1]):\n",
    "            if i in self.cat_feature_idx:\n",
    "                feature_partition = self.split_categorical_feature(X[:, i], y)\n",
    "                # print(f'feature partition: {feature_partition}')\n",
    "                entropy = self.split_entropy(feature_partition.values(), y)\n",
    "                if entropy < min_entropy:\n",
    "                    min_entropy = entropy\n",
    "                    best_f = i\n",
    "                    best_mapping = feature_partition\n",
    "                    is_categorical = True\n",
    "                    # print(f'best f: {best_f}, entropy: {entropy}, feature_partition: {feature_partition}')\n",
    "                    cutoff = None\n",
    "            else:\n",
    "                # print('in else')\n",
    "                sort_permutation = X[:, i].argsort()\n",
    "                for j in range(1, len(y)):\n",
    "                    entropy = self.split_entropy([sort_permutation[:j], sort_permutation[j:]], y)\n",
    "                    # print(f'non cat entropy: {entropy}')\n",
    "                    if entropy < min_entropy:\n",
    "                        min_entropy = entropy\n",
    "                        best_mapping = {'left': sort_permutation[:j], 'right': sort_permutation[j:]}\n",
    "                        best_f = i\n",
    "                        is_categorical = False\n",
    "                        cutoff = (X[:, i][sort_permutation[j-1]] + X[:, i][sort_permutation[j]]) / 2 # mean of the two points\n",
    "\n",
    "                        # print(f'raw: {X[:, i]}')\n",
    "                        # print(f'best mapping: {best_mapping}')\n",
    "                        # print(f'cutoff: {cutoff}')\n",
    "        \n",
    "        return best_mapping, best_f, is_categorical, cutoff\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def generate_tree(self, X: np.array, y: np.array, current_node: TreeNode):\n",
    "        # self.count += 1\n",
    "        # if self.count > 10:\n",
    "        #     return\n",
    "\n",
    "        if self.node_entropy(y) <= self.theta_i:\n",
    "            majority_class = np.argmax(np.bincount(y))\n",
    "            current_node.prediction = majority_class\n",
    "            return\n",
    "        best_mapping, best_f, is_categorical, cutoff = self.split_attribute(X, y)\n",
    "        for branch_name, branch_idx in best_mapping.items():\n",
    "            new_node = TreeNode()\n",
    "            current_node.feature_idx = best_f\n",
    "            current_node.is_categorical = is_categorical\n",
    "            current_node.numeric_split = cutoff\n",
    "\n",
    "            X_branch = X[branch_idx]\n",
    "            y_branch = y[branch_idx]\n",
    "            current_node.mapping[branch_name] = new_node\n",
    "\n",
    "            # if current_node.is_categorical:\n",
    "            #     print(f'bestf: {best_f}')\n",
    "            #     print(X, y)\n",
    "            self.generate_tree(X_branch, y_branch, new_node)\n",
    "        \n",
    "    def fit(self, X: np.array, y: np.array, cat_feature_idx: np.array):\n",
    "        self.num_classes = len(np.unique(y))\n",
    "        self.cat_feature_idx = cat_feature_idx\n",
    "        root = TreeNode()\n",
    "        self.tree = root\n",
    "        self.generate_tree(X, y, root)\n",
    "\n",
    "    def predict(self, X_test: np.array):\n",
    "        preds = []\n",
    "        for row in X_test:\n",
    "            current_node = self.tree\n",
    "            while len(current_node.mapping) > 0:\n",
    "                current_node = current_node.predict(row)\n",
    "            prediction = current_node.predict(row)\n",
    "            preds.append(prediction)\n",
    "\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/ds/lib/python3.7/site-packages/ipykernel_launcher.py:60: RuntimeWarning: divide by zero encountered in log2\n",
      "/usr/local/Caskroom/miniconda/base/envs/ds/lib/python3.7/site-packages/ipykernel_launcher.py:60: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "# test 1: confirm classifier works with mock data\n",
    "\n",
    "X = np.array([[1,1.5], [2,2.3], [5, 5.5]])\n",
    "y = np.array([1,0,1])\n",
    "\n",
    "c = DecisionTreeClassifier()\n",
    "c.fit(X, y, cat_feature_idx=[0])\n",
    "\n",
    "assert np.array_equal(c.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/ds/lib/python3.7/site-packages/ipykernel_launcher.py:60: RuntimeWarning: divide by zero encountered in log2\n",
      "/usr/local/Caskroom/miniconda/base/envs/ds/lib/python3.7/site-packages/ipykernel_launcher.py:60: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "# test 2: confirm classifier works with mock data\n",
    "\n",
    "X = np.array([[6.50, 1.0, 3], [6.9, 1.0, 3]])\n",
    "y = np.array([1, 0])\n",
    "\n",
    "c = DecisionTreeClassifier()\n",
    "c.fit(X, y, cat_feature_idx=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature idx: 0 is_categorical: False numeric_split: 6.7 prediction: None\n",
      "\tvalue left ---feature idx: None is_categorical: None numeric_split: None prediction: 1\n",
      "\tvalue right ---feature idx: None is_categorical: None numeric_split: None prediction: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print tree in ascii\n",
    "\n",
    "print(str(c.tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/Caskroom/miniconda/base/envs/ds/lib/python3.7/site-packages/ipykernel_launcher.py:60: RuntimeWarning: divide by zero encountered in log2\n",
      "/usr/local/Caskroom/miniconda/base/envs/ds/lib/python3.7/site-packages/ipykernel_launcher.py:60: RuntimeWarning: invalid value encountered in multiply\n",
      " 20%|â–ˆâ–ˆ        | 2/10 [00:01<00:06,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing value during evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:02<00:05,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing value during evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average cv score: 0.7506896551724138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from tqdm import trange\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    return (y_true == y_pred).sum() / len(y_true)\n",
    "\n",
    "def load_one_file(filename: str):\n",
    "    data = np.load(filename, allow_pickle=True)\n",
    "    X = data['x']\n",
    "    y = data['y']\n",
    "    example_names = data['example_names']\n",
    "    return X, y, example_names\n",
    "\n",
    "def load_folds(folds: List[int]):\n",
    "    all_X = []\n",
    "    all_y = []\n",
    "    all_example_names = []\n",
    "    for fold in folds:\n",
    "        filename = f'/Users/brwang/Desktop/ml_class/hw0/data/heart_fold{fold}.npz'\n",
    "        X, y, example_names = load_one_file(filename)\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "        all_example_names.append(example_names)\n",
    "\n",
    "    X_folds = np.concatenate(all_X, axis=0)\n",
    "    y_folds = np.concatenate(all_y)\n",
    "    example_names_folds = np.concatenate(all_example_names)\n",
    "        \n",
    "    return X_folds, y_folds, example_names_folds\n",
    "\n",
    "X, y, example_names = load_folds([0, 1])\n",
    "X.shape, y.shape, example_names.shape\n",
    "\n",
    "def cv(num_folds=10):\n",
    "    cv_results = []\n",
    "    ks = []\n",
    "    for test_fold in trange(num_folds):\n",
    "        X_test, y_test, example_names_test = load_folds([test_fold])\n",
    "        train_folds = [fold for fold in range(num_folds) if fold != test_fold]\n",
    "        clf = DecisionTreeClassifier(num_classes=2)\n",
    "        X_train, y_train, example_names_train = load_folds(train_folds)\n",
    "        clf.fit(X_train, y_train, cat_feature_idx=[1, 2, 5, 6, 8, 10, 11, 12])\n",
    "        y_pred = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        cv_results.append(acc)\n",
    "    return cv_results\n",
    "\n",
    "cv_scores = cv()\n",
    "print(f'average cv score: {np.mean(cv_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/ds/lib/python3.7/site-packages/ipykernel_launcher.py:60: RuntimeWarning: divide by zero encountered in log2\n",
      "/usr/local/Caskroom/miniconda/base/envs/ds/lib/python3.7/site-packages/ipykernel_launcher.py:60: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debug using 1 fold\n",
    "\n",
    "X_test, y_test, example_names_test = load_folds([0])\n",
    "train_folds = [fold for fold in range(10) if fold != 0]\n",
    "print(train_folds)\n",
    "# tune_results = get_tune_results(train_folds)\n",
    "# print(f'tune accuracy matrix, fold {test_fold}: \\n{tune_results}')\n",
    "# k, mean_results = get_optimal_k(tune_results)\n",
    "# ks.append(k)\n",
    "# print(f'average accuracy for each k, fold {test_fold}: \\n{mean_results}')\n",
    "# print(f'optimal k for fold {test_fold}: {k}')\n",
    "clf = DecisionTreeClassifier(num_classes=2, theta_i=0)\n",
    "X_train, y_train, example_names_train = load_folds(train_folds)\n",
    "clf.fit(X_train, y_train, cat_feature_idx=[1, 2, 5, 6, 8, 10, 11, 12])\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "acc"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d20419c564893ff7827d87520a6c3b654e0969c6aa9ae3b46a277348f487f0d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
