{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 3a: Implement Perceptron for Heart Disease\n",
    "\n",
    "1. Use step function and $\\eta = 0.1$ and batch size = 4 (ok to use 1 if need be)\n",
    "2. Use TUNE set to choose ‘early stopping’ epoch for each of 10 test folds (maxEpochs = 10,000 but can stop if / when all trainset examples correct)\n",
    "3. Ok to just use ONE tune set (but feel free to use 9 as done in HW1 and HW2)\n",
    "4. Once epochsToUse estimated, train on all 9 folds; use (8/9) epochsToUse\n",
    "5. Report best epoch and min, mean, and max accuracy per train-tune fold \n",
    "6. Compare to Random Forests and kNN test set min, mean, and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def step_function(x: int):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, num_weights, activation_function, learning_rate=0.1):\n",
    "        self.weights = np.zeros(num_weights + 1)\n",
    "        self.activation_function = activation_function\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def fit(self, X: np.array, y: np.array): # X is 3-d array, y is 2-d array with batch size in first dimension\n",
    "        for X_batch, y_batch in zip(X, y):\n",
    "            # print(f'weights before: {self.weights}')\n",
    "            updates = []\n",
    "            assert X_batch.shape[0] == y_batch.shape[0]\n",
    "            for example, y in zip(X_batch, y_batch):\n",
    "                example = np.append(example, -1)\n",
    "                y_bar = self.predict_one(example)\n",
    "                # print(y_bar)\n",
    "                update = self.learning_rate * (y - y_bar) * example\n",
    "                # print(f'example: {example}, update: {update}')\n",
    "                updates.append(update)\n",
    "            self.weights = self.weights + np.sum(updates, axis=0) / X_batch.shape[0]\n",
    "            # print(f'weights after: {self.weights}')\n",
    "\n",
    "    def predict_one(self, example: np.array):\n",
    "        return self.activation_function(self.weights.T @ example)\n",
    "\n",
    "    def predict(self, examples: np.array):\n",
    "        output = []\n",
    "        for example in examples:\n",
    "            example = np.append(example, -1)\n",
    "            output.append(self.predict_one(example))\n",
    "        return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit tests\n",
    "\n",
    "clf = Perceptron(4, step_function)\n",
    "x = np.array([[[1, 2, 3, 1], [2, 3, 4, 1], [2, 3, 4, 1]], [[5, 6, 7, 1], [8, 9, 10, 1], [2, 3, 4, 1]]])\n",
    "y = np.array([[1, 0, 1], [0, 0, 1]])\n",
    "\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 13)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from tqdm import trange\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    return (y_true == y_pred).sum() / len(y_true)\n",
    "\n",
    "def load_one_file(filename: str):\n",
    "    data = np.load(filename, allow_pickle=True)\n",
    "    X = data['x']\n",
    "    y = data['y']\n",
    "    example_names = data['example_names']\n",
    "    return X, y, example_names\n",
    "\n",
    "def load_folds(folds: List[int]):\n",
    "    all_X = []\n",
    "    all_y = []\n",
    "    all_example_names = []\n",
    "    for fold in folds:\n",
    "        filename = f'../hw0/data/heart_fold{fold}.npz'\n",
    "        X, y, example_names = load_one_file(filename)\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "        all_example_names.append(example_names)\n",
    "\n",
    "    X_folds = np.concatenate(all_X, axis=0)\n",
    "    y_folds = np.concatenate(all_y)\n",
    "    example_names_folds = np.concatenate(all_example_names)\n",
    "        \n",
    "    return X_folds, y_folds, example_names_folds\n",
    "\n",
    "X, y, example_names = load_folds([0, 1])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 2, 3), (3, 2))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_batched_data(X: np.array, y: np.array, batch_size):\n",
    "    assert len(X.shape) == 2 and len(y.shape) == 1\n",
    "    # losing some data here\n",
    "    num_batches = X.shape[0] // batch_size\n",
    "    X = X[:num_batches * batch_size]\n",
    "    y = y[:num_batches * batch_size]\n",
    "    X = X.reshape(-1, batch_size, X.shape[1])\n",
    "    y = y.reshape(-1, batch_size)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = create_batched_data(np.ones((7, 3)), np.ones(7), 2)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fold 0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/brwang/Desktop/ml_class/hw0/data/heart_fold0.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     \u001b[39mprint\u001b[39m(ks)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m cv_results\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m cv_scores \u001b[39m=\u001b[39m cv()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39maverage cv score: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(cv_scores)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb Cell 6\u001b[0m in \u001b[0;36mcv\u001b[0;34m(num_folds)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstarting fold \u001b[39m\u001b[39m{\u001b[39;00mtest_fold\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m X_test, y_test, example_names_test \u001b[39m=\u001b[39m load_folds([test_fold])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m train_folds \u001b[39m=\u001b[39m [fold \u001b[39mfor\u001b[39;00m fold \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_folds) \u001b[39mif\u001b[39;00m fold \u001b[39m!=\u001b[39m test_fold]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m best_epoch \u001b[39m=\u001b[39m get_tune_results(train_folds)\n",
      "\u001b[1;32m/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb Cell 6\u001b[0m in \u001b[0;36mload_folds\u001b[0;34m(folds)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m fold \u001b[39min\u001b[39;00m folds:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/Users/brwang/Desktop/ml_class/hw0/data/heart_fold\u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m}\u001b[39;00m\u001b[39m.npz\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     X, y, example_names \u001b[39m=\u001b[39m load_one_file(filename)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     all_X\u001b[39m.\u001b[39mappend(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     all_y\u001b[39m.\u001b[39mappend(y)\n",
      "\u001b[1;32m/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb Cell 6\u001b[0m in \u001b[0;36mload_one_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_one_file\u001b[39m(filename: \u001b[39mstr\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(filename, allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     X \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     y \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds/lib/python3.8/site-packages/numpy/lib/npyio.py:417\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 417\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    418\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/brwang/Desktop/ml_class/hw0/data/heart_fold0.npz'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def get_tune_results(train_tune_folds: List[int], batch_size=4, MAX_EPOCHS=5000): # TODO: set batch size 1 for debugging \n",
    "    for tune_fold in range(len(train_tune_folds)):\n",
    "        X_tune, y_tune, example_names_tune = load_folds([tune_fold])\n",
    "        train_folds = [fold for fold in train_tune_folds if fold != tune_fold]\n",
    "        X_train, y_train, example_names_train = load_folds(train_folds)\n",
    "\n",
    "        clf = Perceptron(X_train.shape[1], step_function)\n",
    "        best_epoch = 0\n",
    "        best_accuracy = 0\n",
    "        for i in trange(MAX_EPOCHS):\n",
    "            perm = np.random.permutation(X_train.shape[0])\n",
    "            X_train = X_train[perm]\n",
    "            y_train = y_train[perm]\n",
    "            X_batched, y_batched = create_batched_data(X_train, y_train, batch_size=batch_size)\n",
    "            clf.fit(X_batched, y_batched)\n",
    "            y_pred_train = clf.predict(X_train)\n",
    "            train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "            if train_accuracy == 1:\n",
    "                print(f\"achieved perfect train accuracy at epoch {i}\")\n",
    "                break\n",
    "            y_pred = clf.predict(X_tune)\n",
    "            tune_accuracy = accuracy_score(y_tune, y_pred)\n",
    "            if tune_accuracy > best_accuracy:\n",
    "                best_epoch = i\n",
    "                best_accuracy = tune_accuracy\n",
    "                # print(best_accuracy, best_epoch)\n",
    "            # if i % 1000 == 0:\n",
    "            #     print(f'epoch {i}: ')\n",
    "            #     print(np.abs(clf.weights).sum(), np.abs(clf.weights).max(), np.abs(clf.weights).min()) # print min max sum of absolute value of weights per epoch\n",
    "            # print absolute value of weight updates\n",
    "            # okay try eta / 10, eta / 100\n",
    "        break\n",
    "        \n",
    "    print(f'best epoch: {best_epoch}')\n",
    "    print(f'last train accuracy: {train_accuracy}')\n",
    "    print(f'best tune accuracy: {best_accuracy}')\n",
    "    return best_epoch\n",
    "\n",
    "def cv(num_folds=10):\n",
    "    cv_results = []\n",
    "    ks = []\n",
    "    for test_fold in range(num_folds):\n",
    "        print(f'starting fold {test_fold}')\n",
    "        start = time.time()\n",
    "        X_test, y_test, example_names_test = load_folds([test_fold])\n",
    "        train_folds = [fold for fold in range(num_folds) if fold != test_fold]\n",
    "        best_epoch = get_tune_results(train_folds)\n",
    "        X_train, y_train, example_names_train = load_folds(train_folds)\n",
    "        clf = Perceptron(X_train.shape[1], step_function)\n",
    "        for i in range(int(best_epoch * (8/9))):\n",
    "            perm = np.random.permutation(X_train.shape[0])\n",
    "            X_train = X_train[perm]\n",
    "            y_train = y_train[perm]\n",
    "            X_batched, y_batched = create_batched_data(X_train, y_train, batch_size=4)\n",
    "            clf.fit(X_batched, y_batched)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        cv_results.append(acc)\n",
    "        end = time.time()\n",
    "        print(f'time for fold: {end - start}')\n",
    "        # break\n",
    "\n",
    "    print(ks)\n",
    "    return cv_results\n",
    "\n",
    "cv_scores = cv()\n",
    "print(f'average cv score: {np.mean(cv_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min cv score: 0.6551724137931034\n",
      "max cv score: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(f'min cv score: {np.min(cv_scores)}')\n",
    "print(f'max cv score: {np.max(cv_scores)}')\n",
    "\n",
    "# before bugfix\n",
    "# min cv score: 0.6551724137931034\n",
    "# max cv score: 0.9333333333333333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3b\n",
    "\n",
    "1. Repeat above but use one layer of 128 ReLU hidden units & backprop\n",
    "2. Use Sigmoid as the activation function for the output\n",
    "3. If maxEpochs = 10,000 runs too slowly, use 5,000 or 1,000\n",
    "4. Optional: try #HUs in {16, 32, 64, 128, 256, 512, 1024, …, YouChooseMax} and use the best #HUs + stopping epoch on tune set per train-test fold\n",
    "5. Compare to results discussed in HW3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23413753346060412"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, eta=0.01):\n",
    "        kaiming_std = np.sqrt(2/13) # kaiming initialization\n",
    "        self.hidden_weights = np.random.normal(0, kaiming_std, size=(128, 13))\n",
    "        self.hidden_bias = np.random.normal(0, kaiming_std, size=128)\n",
    "        self.output_weights = np.random.normal(0, kaiming_std, size=128)\n",
    "        self.output_bias = np.random.normal(0, kaiming_std)\n",
    "        self.backprop_state = {}\n",
    "        self.eta = eta\n",
    "\n",
    "    def relu(self, x): # vectorized function\n",
    "        return np.maximum(x, 0) \n",
    "\n",
    "    def sigmoid(self, x): # vectorized function\n",
    "        return 1 / (1 + np.exp(-x)) \n",
    "\n",
    "    def fit(self, X: np.array, y: np.array): # X is 3-d array, y is 2-d array with batch size in first dimension\n",
    "        for X_batch, y_batch in zip(X, y):\n",
    "            # print(f'weights before: {self.weights}')\n",
    "            total_hidden_update = np.zeros((128, 13))\n",
    "            total_output_update = np.zeros(128)\n",
    "            total_hidden_bias_update = np.zeros(128)\n",
    "            total_output_bias_update = 0\n",
    "\n",
    "            assert X_batch.shape[0] == y_batch.shape[0]\n",
    "            for example, y in zip(X_batch, y_batch):\n",
    "                y_bar = self.forward_prop(example)\n",
    "                hidden_update, output_update, hidden_error, output_error = self.back_prop(example, y)\n",
    "                total_hidden_update += hidden_update\n",
    "                total_output_update += output_update\n",
    "                total_hidden_bias_update += hidden_error\n",
    "                total_output_bias_update += output_error\n",
    "\n",
    "            self.hidden_weights -= total_hidden_update / X_batch.shape[0]\n",
    "            self.output_weights -= total_output_update / X_batch.shape[0]\n",
    "            self.hidden_bias -= total_hidden_bias_update / X_batch.shape[0]\n",
    "            self.output_bias -= total_output_bias_update / X_batch.shape[0]\n",
    "            # print(f'weights after: {self.weights}')\n",
    "\n",
    "    def back_prop(self, x, y):\n",
    "        output_error = (self.backprop_state['a_L'] - y)*(1 - self.backprop_state['a_L'])*self.backprop_state['a_L']\n",
    "        output_update = self.backprop_state['a_L-1'] * output_error\n",
    "\n",
    "        hidden_error = output_error * self.output_weights * self.backprop_state['sigprime(z_L-1)']\n",
    "        broadcasted_example = np.broadcast_to(x, (128, 13))\n",
    "        hidden_update = np.broadcast_to(hidden_error, (13, 128)).T # * broadcasted_example\n",
    "\n",
    "        return hidden_update, output_update, hidden_error, output_error\n",
    "\n",
    "\n",
    "    def forward_prop(self, x):\n",
    "        x = self.hidden_weights @ x + self.hidden_bias\n",
    "        self.backprop_state['z_L-1'] = x\n",
    "        self.backprop_state['sigprime(z_L-1)'] = np.where(x > 0, 1, 0)\n",
    "        x = self.relu(x)\n",
    "        self.backprop_state['a_L-1'] = x\n",
    "        x = self.output_weights @ x + self.output_bias\n",
    "        self.backprop_state['z_L'] = x\n",
    "        x = self.sigmoid(x)\n",
    "        self.backprop_state['a_L'] = x\n",
    "\n",
    "        # print(self.backprop_state)\n",
    "        return x \n",
    "\n",
    "\n",
    "    def predict(self, examples: np.array):\n",
    "        output = []\n",
    "        for example in examples:\n",
    "            output.append(self.forward_prop(example))\n",
    "        return np.array(output)\n",
    "\n",
    "\n",
    "clf = NeuralNetwork()\n",
    "clf.forward_prop(np.ones(13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [1.6872583e-06]\n",
      "100: [1.68725827e-06]\n",
      "200: [1.68725824e-06]\n",
      "300: [1.68725821e-06]\n",
      "400: [1.68725817e-06]\n",
      "500: [1.68725814e-06]\n",
      "600: [1.68725811e-06]\n",
      "700: [1.68725808e-06]\n",
      "800: [1.68725804e-06]\n",
      "900: [1.68725801e-06]\n"
     ]
    }
   ],
   "source": [
    "# fit to random vector\n",
    "\n",
    "x = np.random.normal(size=(1, 1, 13))\n",
    "y = np.ones((1, 1))\n",
    "for i in range(1000):\n",
    "    clf.fit(x, y)\n",
    "    if (i % 100) == 0:\n",
    "        print(f'{i}: {y[0] - clf.forward_prop(x[0][0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X: np.array, means=None, std=None):\n",
    "    if means is None or std is None:\n",
    "        means = X.mean(axis=0)\n",
    "        std = X.std(axis=0)\n",
    "\n",
    "    return (X - means) / std, means, std\n",
    "\n",
    "\n",
    "def min_max_normalize(X: np.array):\n",
    "    return (X - X.min()) / (X.max() - X.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.263676837555066, -2.8574475022613934)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try on 1 fold\n",
    "\n",
    "X_train, y_train, _ = load_folds([0])\n",
    "X_train, means, std = normalize(X_train)\n",
    "# X_train = min_max_normalize(X_train)\n",
    "\n",
    "X_train.max(), X_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 4, 13)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batched, y_batched = create_batched_data(X_train, y_train, batch_size=4)\n",
    "X_batched.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 164/1000 [00:00<00:01, 820.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.6\n",
      "100: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 330/1000 [00:00<00:00, 808.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200: 0.9666666666666667\n",
      "300: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 491/1000 [00:00<00:00, 788.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400: 0.9666666666666667\n",
      "500: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 731/1000 [00:00<00:00, 789.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600: 0.9666666666666667\n",
      "700: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 893/1000 [00:01<00:00, 799.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800: 0.9666666666666667\n",
      "900: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 797.33it/s]\n"
     ]
    }
   ],
   "source": [
    "clf = NeuralNetwork()\n",
    "best_epoch = 0\n",
    "best_accuracy = 0\n",
    "for i in trange(1000):\n",
    "    # print(X_batched.shape)\n",
    "    clf.fit(X_batched, y_batched)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_train = np.round(y_pred_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    if i % 100 == 0:\n",
    "        # print(y_pred_train)\n",
    "        print(f'{i}: {train_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fold 0\n",
      "Xtune: (30, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:11<00:00, 89.13it/s]\n",
      "/var/folders/lr/597pxhmx2z78r4vysc_dvsth0000gn/T/ipykernel_82293/481716268.py:18: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 21\n",
      "last train accuracy: 0.9101123595505618\n",
      "best tune accuracy: 0.8666666666666667\n",
      "test acc 0: 0.6333333333333333\n",
      "time for fold: 11.384541273117065\n",
      "starting fold 1\n",
      "Xtune: (30, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:10<00:00, 98.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 86\n",
      "last train accuracy: 0.9282700421940928\n",
      "best tune accuracy: 0.8666666666666667\n",
      "test acc 1: 0.4666666666666667\n",
      "time for fold: 10.736838340759277\n",
      "starting fold 2\n",
      "Xtune: (30, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 143/1000 [00:01<00:08, 98.52it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mprint\u001b[39m(ks)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m cv_results\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m cv()\n",
      "\u001b[1;32m/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb Cell 15\u001b[0m in \u001b[0;36mcv\u001b[0;34m(num_folds)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m X_test, y_test, example_names_test \u001b[39m=\u001b[39m load_folds([test_fold])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m train_folds \u001b[39m=\u001b[39m [fold \u001b[39mfor\u001b[39;00m fold \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_folds) \u001b[39mif\u001b[39;00m fold \u001b[39m!=\u001b[39m test_fold]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m best_epoch \u001b[39m=\u001b[39m get_tune_results(train_folds)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m X_train, y_train, example_names_train \u001b[39m=\u001b[39m load_folds(train_folds)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m clf \u001b[39m=\u001b[39m NeuralNetwork()\n",
      "\u001b[1;32m/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb Cell 15\u001b[0m in \u001b[0;36mget_tune_results\u001b[0;34m(train_tune_folds, batch_size, MAX_EPOCHS)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m X_batched, y_batched \u001b[39m=\u001b[39m create_batched_data(X_train, y_train, batch_size\u001b[39m=\u001b[39mbatch_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# print(X_batched.shape)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_batched, y_batched)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m y_pred_train \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(X_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m y_pred_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(y_pred_train)\n",
      "\u001b[1;32m/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb Cell 15\u001b[0m in \u001b[0;36mNeuralNetwork.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;00m example, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(X_batch, y_batch):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     y_bar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_prop(example)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     hidden_update, output_update, hidden_error, output_error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mback_prop(example, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     total_hidden_update \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m hidden_update\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     total_output_update \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m output_update\n",
      "\u001b[1;32m/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb Cell 15\u001b[0m in \u001b[0;36mNeuralNetwork.back_prop\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m hidden_error \u001b[39m=\u001b[39m output_error \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_weights \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackprop_state[\u001b[39m'\u001b[39m\u001b[39msigprime(z_L-1)\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m broadcasted_example \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbroadcast_to(x, (\u001b[39m128\u001b[39m, \u001b[39m13\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m hidden_update \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mbroadcast_to(hidden_error, (\u001b[39m13\u001b[39;49m, \u001b[39m128\u001b[39;49m))\u001b[39m.\u001b[39mT \u001b[39m# * broadcasted_example\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bryanwang/Desktop/ml_class/hw3/hw3.ipynb#X14sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mreturn\u001b[39;00m hidden_update, output_update, hidden_error, output_error\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ds/lib/python3.8/site-packages/numpy/lib/stride_tricks.py:366\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[0;34m(array, shape, subok)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_broadcast_to_dispatcher\u001b[39m(array, shape, subok\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m     \u001b[39mreturn\u001b[39;00m (array,)\n\u001b[0;32m--> 366\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_broadcast_to_dispatcher, module\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    367\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbroadcast_to\u001b[39m(array, shape, subok\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    368\u001b[0m     \u001b[39m\"\"\"Broadcast an array to a new shape.\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \n\u001b[1;32m    370\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39m           [1, 2, 3]])\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    411\u001b[0m     \u001b[39mreturn\u001b[39;00m _broadcast_to(array, shape, subok\u001b[39m=\u001b[39msubok, readonly\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def get_tune_results(train_tune_folds: List[int], batch_size=4, MAX_EPOCHS=1000): # TODO: set batch size 1 for debugging \n",
    "    for tune_fold in range(len(train_tune_folds)):\n",
    "        X_tune, y_tune, example_names_tune = load_folds([tune_fold])\n",
    "        train_folds = [fold for fold in train_tune_folds if fold != tune_fold]\n",
    "        X_train, y_train, example_names_train = load_folds(train_folds)\n",
    "\n",
    "        X_train, means, std = normalize(X_train)\n",
    "        X_tune, _, _ = normalize(X_tune, means=means, std=std)\n",
    "\n",
    "        print(f'Xtune: {X_tune.shape}')\n",
    "\n",
    "        clf = NeuralNetwork()\n",
    "        best_epoch = 0\n",
    "        best_accuracy = 0\n",
    "        for i in trange(MAX_EPOCHS):\n",
    "            perm = np.random.permutation(X_train.shape[0])\n",
    "            X_train = X_train[perm]\n",
    "            y_train = y_train[perm]\n",
    "            X_batched, y_batched = create_batched_data(X_train, y_train, batch_size=batch_size)\n",
    "            # print(X_batched.shape)\n",
    "            clf.fit(X_batched, y_batched)\n",
    "            y_pred_train = clf.predict(X_train)\n",
    "            y_pred_train = np.round(y_pred_train)\n",
    "            train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "            if train_accuracy == 1:\n",
    "                print(f\"achieved perfect train accuracy at epoch {i}\")\n",
    "                break\n",
    "            y_pred = clf.predict(X_tune)\n",
    "            y_pred = np.round(y_pred)\n",
    "            tune_accuracy = accuracy_score(y_tune, y_pred)\n",
    "            if tune_accuracy > best_accuracy:\n",
    "                best_epoch = i\n",
    "                best_accuracy = tune_accuracy\n",
    "                # print(best_accuracy, best_epoch)\n",
    "            # if i % 1000 == 0:\n",
    "            #     print(f'epoch {i}: ')\n",
    "            #     print(np.abs(clf.weights).sum(), np.abs(clf.weights).max(), np.abs(clf.weights).min()) # print min max sum of absolute value of weights per epoch\n",
    "            # print absolute value of weight updates\n",
    "            # okay try eta / 10, eta / 100\n",
    "        break\n",
    "        \n",
    "    print(f'best epoch: {best_epoch}')\n",
    "    print(f'last train accuracy: {train_accuracy}')\n",
    "    print(f'best tune accuracy: {best_accuracy}')\n",
    "    return best_epoch\n",
    "\n",
    "def cv(num_folds=10):\n",
    "    cv_results = []\n",
    "    ks = []\n",
    "    for test_fold in range(num_folds):\n",
    "        print(f'starting fold {test_fold}')\n",
    "        start = time.time()\n",
    "        X_test, y_test, example_names_test = load_folds([test_fold])\n",
    "        train_folds = [fold for fold in range(num_folds) if fold != test_fold]\n",
    "        best_epoch = get_tune_results(train_folds)\n",
    "        X_train, y_train, example_names_train = load_folds(train_folds)\n",
    "\n",
    "        X_train, means, std = normalize(X_train)\n",
    "        X_test, _, _ = normalize(X_test, means=means, std=std)\n",
    "        clf = NeuralNetwork()\n",
    "        for i in range(int(best_epoch * (8/9))):\n",
    "            perm = np.random.permutation(X_train.shape[0])\n",
    "            X_train = X_train[perm]\n",
    "            y_train = y_train[perm]\n",
    "            X_batched, y_batched = create_batched_data(X_train, y_train, batch_size=4)\n",
    "            clf.fit(X_batched, y_batched)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_pred = np.round(y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f'test acc {test_fold}: {acc}')\n",
    "        cv_results.append(acc)\n",
    "        end = time.time()\n",
    "        print(f'time for fold: {end - start}')\n",
    "        # break\n",
    "\n",
    "    print(ks)\n",
    "    return cv_results\n",
    "\n",
    "\n",
    "\n",
    "cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebf4d58f2b06e9f21676e768ca6276364ab43d26f7d392ff17c91d23028c0e8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
