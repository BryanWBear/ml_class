{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 3a: Implement Perceptron for Heart Disease\n",
    "\n",
    "1. Use step function and $\\eta = 0.1$ and batch size = 4 (ok to use 1 if need be)\n",
    "2. Use TUNE set to choose ‘early stopping’ epoch for each of 10 test folds (maxEpochs = 10,000 but can stop if / when all trainset examples correct)\n",
    "3. Ok to just use ONE tune set (but feel free to use 9 as done in HW1 and HW2)\n",
    "4. Once epochsToUse estimated, train on all 9 folds; use (8/9) epochsToUse\n",
    "5. Report best epoch and min, mean, and max accuracy per train-tune fold \n",
    "6. Compare to Random Forests and kNN test set min, mean, and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def step_function(x: int):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, num_weights, activation_function, learning_rate=0.1):\n",
    "        self.weights = np.zeros(num_weights + 1)\n",
    "        self.activation_function = activation_function\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def fit(self, X: np.array, y: np.array): # X is 3-d array, y is 2-d array with batch size in first dimension\n",
    "        for X_batch, y_batch in zip(X, y):\n",
    "            # print(f'weights before: {self.weights}')\n",
    "            updates = []\n",
    "            assert X_batch.shape[0] == y_batch.shape[0]\n",
    "            for example, y in zip(X_batch, y_batch):\n",
    "                example = np.append(example, -1)\n",
    "                y_bar = self.predict_one(example)\n",
    "                # print(y_bar)\n",
    "                update = self.learning_rate * (y - y_bar) * example\n",
    "                # print(f'example: {example}, update: {update}')\n",
    "                updates.append(update)\n",
    "            self.weights = self.weights + np.sum(updates, axis=0) / X_batch.shape[0]\n",
    "            # print(f'weights after: {self.weights}')\n",
    "\n",
    "    def predict_one(self, example: np.array):\n",
    "        return self.activation_function(self.weights.T @ example)\n",
    "\n",
    "    def predict(self, examples: np.array):\n",
    "        output = []\n",
    "        for example in examples:\n",
    "            example = np.append(example, -1)\n",
    "            output.append(self.predict_one(example))\n",
    "        return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit tests\n",
    "\n",
    "clf = Perceptron(4, step_function)\n",
    "x = np.array([[[1, 2, 3, 1], [2, 3, 4, 1], [2, 3, 4, 1]], [[5, 6, 7, 1], [8, 9, 10, 1], [2, 3, 4, 1]]])\n",
    "y = np.array([[1, 0, 1], [0, 0, 1]])\n",
    "\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 13)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from tqdm import trange\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    return (y_true == y_pred).sum() / len(y_true)\n",
    "\n",
    "def load_one_file(filename: str):\n",
    "    data = np.load(filename, allow_pickle=True)\n",
    "    X = data['x']\n",
    "    y = data['y']\n",
    "    example_names = data['example_names']\n",
    "    return X, y, example_names\n",
    "\n",
    "def load_folds(folds: List[int]):\n",
    "    all_X = []\n",
    "    all_y = []\n",
    "    all_example_names = []\n",
    "    for fold in folds:\n",
    "        filename = f'/Users/brwang/Desktop/ml_class/hw0/data/heart_fold{fold}.npz'\n",
    "        X, y, example_names = load_one_file(filename)\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "        all_example_names.append(example_names)\n",
    "\n",
    "    X_folds = np.concatenate(all_X, axis=0)\n",
    "    y_folds = np.concatenate(all_y)\n",
    "    example_names_folds = np.concatenate(all_example_names)\n",
    "        \n",
    "    return X_folds, y_folds, example_names_folds\n",
    "\n",
    "X, y, example_names = load_folds([0, 1])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 2, 3), (3, 2))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_batched_data(X: np.array, y: np.array, batch_size):\n",
    "    assert len(X.shape) == 2 and len(y.shape) == 1\n",
    "    # losing some data here\n",
    "    num_batches = X.shape[0] // batch_size\n",
    "    X = X[:num_batches * batch_size]\n",
    "    y = y[:num_batches * batch_size]\n",
    "    X = X.reshape(-1, batch_size, X.shape[1])\n",
    "    y = y.reshape(-1, batch_size)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = create_batched_data(np.ones((7, 3)), np.ones(7), 2)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/5000 [00:00<00:43, 115.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:42<00:00, 118.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 336\n",
      "last train accuracy: 0.8127340823970037\n",
      "best tune accuracy: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/5000 [00:00<00:35, 142.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0]\n",
      "time for fold: 43.482462882995605\n",
      "starting fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:35<00:00, 139.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 493\n",
      "last train accuracy: 0.8523206751054853\n",
      "best tune accuracy: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/5000 [00:00<00:34, 143.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 0]\n",
      "time for fold: 37.922394037246704\n",
      "starting fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:41<00:00, 119.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 574\n",
      "last train accuracy: 0.759493670886076\n",
      "best tune accuracy: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/5000 [00:00<00:34, 143.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 0 0 0 1 1 1]\n",
      "time for fold: 44.2390398979187\n",
      "starting fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:39<00:00, 126.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 476\n",
      "last train accuracy: 0.8396624472573839\n",
      "best tune accuracy: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/5000 [00:00<00:39, 127.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "time for fold: 41.660305976867676\n",
      "starting fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:35<00:00, 140.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 358\n",
      "last train accuracy: 0.8607594936708861\n",
      "best tune accuracy: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/5000 [00:00<00:36, 137.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 0 0 0 0 0 1 1 0 1]\n",
      "time for fold: 36.98588418960571\n",
      "starting fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:35<00:00, 141.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 457\n",
      "last train accuracy: 0.8649789029535865\n",
      "best tune accuracy: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/5000 [00:00<00:35, 142.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "time for fold: 37.04566192626953\n",
      "starting fold 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [53:14<00:00,  1.56it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 697\n",
      "last train accuracy: 0.8734177215189873\n",
      "best tune accuracy: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/5000 [00:00<00:54, 91.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 1 0 1 0 0 1 1 0 1 0 0 0 0]\n",
      "time for fold: 3200.5784060955048\n",
      "starting fold 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 888/5000 [00:08<00:28, 146.38it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def get_tune_results(train_tune_folds: List[int], batch_size=4, MAX_EPOCHS=5000): # TODO: set batch size 1 for debugging \n",
    "    for tune_fold in range(len(train_tune_folds)):\n",
    "        X_tune, y_tune, example_names_tune = load_folds([tune_fold])\n",
    "        train_folds = [fold for fold in train_tune_folds if fold != tune_fold]\n",
    "        X_train, y_train, example_names_train = load_folds(train_folds)\n",
    "\n",
    "        clf = Perceptron(X_train.shape[1], step_function)\n",
    "        best_epoch = 0\n",
    "        best_accuracy = 0\n",
    "        for i in trange(MAX_EPOCHS):\n",
    "            perm = np.random.permutation(X_train.shape[0])\n",
    "            X_train = X_train[perm]\n",
    "            y_train = y_train[perm]\n",
    "            X_batched, y_batched = create_batched_data(X_train, y_train, batch_size=batch_size)\n",
    "            clf.fit(X_batched, y_batched)\n",
    "            y_pred_train = clf.predict(X_train)\n",
    "            train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "            if train_accuracy == 1:\n",
    "                print(f\"achieved perfect train accuracy at epoch {i}\")\n",
    "                break\n",
    "            y_pred = clf.predict(X_tune)\n",
    "            tune_accuracy = accuracy_score(y_tune, y_pred)\n",
    "            if tune_accuracy > best_accuracy:\n",
    "                best_epoch = i\n",
    "                best_accuracy = tune_accuracy\n",
    "                # print(best_accuracy, best_epoch)\n",
    "            # if i % 1000 == 0:\n",
    "            #     print(f'epoch {i}: ')\n",
    "            #     print(np.abs(clf.weights).sum(), np.abs(clf.weights).max(), np.abs(clf.weights).min()) # print min max sum of absolute value of weights per epoch\n",
    "            # print absolute value of weight updates\n",
    "            # okay try eta / 10, eta / 100\n",
    "        break\n",
    "        \n",
    "    print(f'best epoch: {best_epoch}')\n",
    "    print(f'last train accuracy: {train_accuracy}')\n",
    "    print(f'best tune accuracy: {best_accuracy}')\n",
    "    return best_epoch\n",
    "\n",
    "def cv(num_folds=10):\n",
    "    cv_results = []\n",
    "    ks = []\n",
    "    for test_fold in range(num_folds):\n",
    "        print(f'starting fold {test_fold}')\n",
    "        start = time.time()\n",
    "        X_test, y_test, example_names_test = load_folds([test_fold])\n",
    "        train_folds = [fold for fold in range(num_folds) if fold != test_fold]\n",
    "        best_epoch = get_tune_results(train_folds)\n",
    "        X_train, y_train, example_names_train = load_folds(train_folds)\n",
    "        clf = Perceptron(X_train.shape[1], step_function)\n",
    "        for i in range(int(best_epoch * (8/9))):\n",
    "            perm = np.random.permutation(X_train.shape[0])\n",
    "            X_train = X_train[perm]\n",
    "            y_train = y_train[perm]\n",
    "            X_batched, y_batched = create_batched_data(X_train, y_train, batch_size=4)\n",
    "            clf.fit(X_batched, y_batched)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        cv_results.append(acc)\n",
    "        end = time.time()\n",
    "        print(f'time for fold: {end - start}')\n",
    "        # break\n",
    "\n",
    "    print(ks)\n",
    "    return cv_results\n",
    "\n",
    "cv_scores = cv()\n",
    "print(f'average cv score: {np.mean(cv_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min cv score: 0.6551724137931034\n",
      "max cv score: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(f'min cv score: {np.min(cv_scores)}')\n",
    "print(f'max cv score: {np.max(cv_scores)}')\n",
    "\n",
    "# before bugfix\n",
    "# min cv score: 0.6551724137931034\n",
    "# max cv score: 0.9333333333333333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3b\n",
    "\n",
    "1. Repeat above but use one layer of 128 ReLU hidden units & backprop\n",
    "2. Use Sigmoid as the activation function for the output\n",
    "3. If maxEpochs = 10,000 runs too slowly, use 5,000 or 1,000\n",
    "4. Optional: try #HUs in {16, 32, 64, 128, 256, 512, 1024, …, YouChooseMax} and use the best #HUs + stopping epoch on tune set per train-test fold\n",
    "5. Compare to results discussed in HW3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8993195841921252"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        kaiming_std = np.sqrt(2/13) # kaiming initialization\n",
    "        self.hidden_weights = np.random.normal(0, kaiming_std, size=(128, 13))\n",
    "        self.output_weights = np.random.normal(0, kaiming_std, size=128)\n",
    "        self.relu = lambda x: np.maximum(x, 0) # vectorized function\n",
    "        self.sigmoid = lambda x: 1 / (1 + math.exp(-x)) # scalar function\n",
    "\n",
    "    def predict(self, examples: np.array):\n",
    "        output = []\n",
    "        for example in examples:\n",
    "            example = np.append(example, 1)\n",
    "            output.append(self.predict_one(example))\n",
    "        return np.array(output)\n",
    "    \n",
    "    def predict_one(self, example: np.array):\n",
    "        v = self.hidden_weights @ example\n",
    "        v = self.relu(v)\n",
    "        v = self.output_weights @ v\n",
    "        return self.sigmoid(v)\n",
    "\n",
    "clf = NeuralNetwork()\n",
    "clf.predict_one(np.ones(13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d20419c564893ff7827d87520a6c3b654e0969c6aa9ae3b46a277348f487f0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
