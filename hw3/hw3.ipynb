{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 3a: Implement Perceptron for Heart Disease\n",
    "\n",
    "1. Use step function and $\\eta = 0.1$ and batch size = 4 (ok to use 1 if need be)\n",
    "2. Use TUNE set to choose ‘early stopping’ epoch for each of 10 test folds (maxEpochs = 10,000 but can stop if / when all trainset examples correct)\n",
    "3. Ok to just use ONE tune set (but feel free to use 9 as done in HW1 and HW2)\n",
    "4. Once epochsToUse estimated, train on all 9 folds; use (8/9) epochsToUse\n",
    "5. Report best epoch and min, mean, and max accuracy per train-tune fold \n",
    "6. Compare to Random Forests and kNN test set min, mean, and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def step_function(x: int):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, num_weights, activation_function, learning_rate=0.1):\n",
    "        self.weights = np.zeros(num_weights + 1)\n",
    "        self.activation_function = activation_function\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def fit(self, X: np.array, y: np.array): # X is 3-d array, y is 2-d array with batch size in first dimension\n",
    "        for X_batch, y_batch in zip(X, y):\n",
    "            # print(f'weights before: {self.weights}')\n",
    "            updates = []\n",
    "            assert X_batch.shape[0] == y_batch.shape[0]\n",
    "            for example, y in zip(X_batch, y_batch):\n",
    "                example = np.append(example, -1)\n",
    "                y_bar = self.predict_one(example)\n",
    "                # print(y_bar)\n",
    "                update = self.learning_rate * (y - y_bar) * example\n",
    "                # print(f'example: {example}, update: {update}')\n",
    "                updates.append(update)\n",
    "            self.weights = self.weights + np.sum(updates, axis=0) / X_batch.shape[0]\n",
    "            # print(f'weights after: {self.weights}')\n",
    "\n",
    "    def predict_one(self, example: np.array):\n",
    "        return self.activation_function(self.weights.T @ example)\n",
    "\n",
    "    def predict(self, examples: np.array):\n",
    "        output = []\n",
    "        for example in examples:\n",
    "            example = np.append(example, -1)\n",
    "            output.append(self.predict_one(example))\n",
    "        return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit tests\n",
    "\n",
    "clf = Perceptron(4, step_function)\n",
    "x = np.array([[[1, 2, 3, 1], [2, 3, 4, 1], [2, 3, 4, 1]], [[5, 6, 7, 1], [8, 9, 10, 1], [2, 3, 4, 1]]])\n",
    "y = np.array([[1, 0, 1], [0, 0, 1]])\n",
    "\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 13)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from tqdm import trange\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    return (y_true == y_pred).sum() / len(y_true)\n",
    "\n",
    "def load_one_file(filename: str):\n",
    "    data = np.load(filename, allow_pickle=True)\n",
    "    X = data['x']\n",
    "    y = data['y']\n",
    "    example_names = data['example_names']\n",
    "    return X, y, example_names\n",
    "\n",
    "def load_folds(folds: List[int]):\n",
    "    all_X = []\n",
    "    all_y = []\n",
    "    all_example_names = []\n",
    "    for fold in folds:\n",
    "        filename = f'../hw0/data/heart_fold{fold}.npz'\n",
    "        X, y, example_names = load_one_file(filename)\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "        all_example_names.append(example_names)\n",
    "\n",
    "    X_folds = np.concatenate(all_X, axis=0)\n",
    "    y_folds = np.concatenate(all_y)\n",
    "    example_names_folds = np.concatenate(all_example_names)\n",
    "        \n",
    "    return X_folds, y_folds, example_names_folds\n",
    "\n",
    "X, y, example_names = load_folds([0, 1])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 2, 3), (3, 2))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_batched_data(X: np.array, y: np.array, batch_size):\n",
    "    assert len(X.shape) == 2 and len(y.shape) == 1\n",
    "    # losing some data here\n",
    "    num_batches = X.shape[0] // batch_size\n",
    "    X = X[:num_batches * batch_size]\n",
    "    y = y[:num_batches * batch_size]\n",
    "    X = X.reshape(-1, batch_size, X.shape[1])\n",
    "    y = y.reshape(-1, batch_size)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = create_batched_data(np.ones((7, 3)), np.ones(7), 2)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:21<00:00, 228.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 440\n",
      "last train accuracy: 0.8089887640449438\n",
      "best tune accuracy: 0.8333333333333334\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 0]\n",
      "time for fold: 22.98461890220642\n",
      "starting fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:19<00:00, 259.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 493\n",
      "last train accuracy: 0.510548523206751\n",
      "best tune accuracy: 0.8333333333333334\n",
      "[1 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 0]\n",
      "time for fold: 20.548422813415527\n",
      "starting fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:19<00:00, 259.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 378\n",
      "last train accuracy: 0.759493670886076\n",
      "best tune accuracy: 0.8333333333333334\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "time for fold: 20.231415033340454\n",
      "starting fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:19<00:00, 259.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 527\n",
      "last train accuracy: 0.7215189873417721\n",
      "best tune accuracy: 0.8333333333333334\n",
      "[1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 0]\n",
      "time for fold: 20.5969021320343\n",
      "starting fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:19<00:00, 259.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 395\n",
      "last train accuracy: 0.8523206751054853\n",
      "best tune accuracy: 0.8333333333333334\n",
      "[1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0]\n",
      "time for fold: 20.26486897468567\n",
      "starting fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:19<00:00, 259.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 380\n",
      "last train accuracy: 0.8481012658227848\n",
      "best tune accuracy: 0.8333333333333334\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "time for fold: 20.251226902008057\n",
      "starting fold 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:19<00:00, 258.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 632\n",
      "last train accuracy: 0.8818565400843882\n",
      "best tune accuracy: 0.8333333333333334\n",
      "[1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0]\n",
      "time for fold: 20.921074867248535\n",
      "starting fold 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [33:17<00:00,  2.50it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 336\n",
      "last train accuracy: 0.8613445378151261\n",
      "best tune accuracy: 0.8333333333333334\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "time for fold: 1998.010136127472\n",
      "starting fold 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:19<00:00, 254.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 347\n",
      "last train accuracy: 0.8529411764705882\n",
      "best tune accuracy: 0.8333333333333334\n",
      "[0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1]\n",
      "time for fold: 20.559474229812622\n",
      "starting fold 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:19<00:00, 252.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 858\n",
      "last train accuracy: 0.8235294117647058\n",
      "best tune accuracy: 0.8333333333333334\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1]\n",
      "time for fold: 22.022316932678223\n",
      "[]\n",
      "average cv score: 0.6795402298850574\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def get_tune_results(train_tune_folds: List[int], batch_size=4, MAX_EPOCHS=5000): # TODO: set batch size 1 for debugging \n",
    "    for tune_fold in range(len(train_tune_folds)):\n",
    "        X_tune, y_tune, example_names_tune = load_folds([tune_fold])\n",
    "        train_folds = [fold for fold in train_tune_folds if fold != tune_fold]\n",
    "        X_train, y_train, example_names_train = load_folds(train_folds)\n",
    "\n",
    "        clf = Perceptron(X_train.shape[1], step_function)\n",
    "        best_epoch = 0\n",
    "        best_accuracy = 0\n",
    "        for i in trange(MAX_EPOCHS):\n",
    "            perm = np.random.permutation(X_train.shape[0])\n",
    "            X_train = X_train[perm]\n",
    "            y_train = y_train[perm]\n",
    "            X_batched, y_batched = create_batched_data(X_train, y_train, batch_size=batch_size)\n",
    "            clf.fit(X_batched, y_batched)\n",
    "            y_pred_train = clf.predict(X_train)\n",
    "            train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "            if train_accuracy == 1:\n",
    "                print(f\"achieved perfect train accuracy at epoch {i}\")\n",
    "                break\n",
    "            y_pred = clf.predict(X_tune)\n",
    "            tune_accuracy = accuracy_score(y_tune, y_pred)\n",
    "            if tune_accuracy > best_accuracy:\n",
    "                best_epoch = i\n",
    "                best_accuracy = tune_accuracy\n",
    "                # print(best_accuracy, best_epoch)\n",
    "            # if i % 1000 == 0:\n",
    "            #     print(f'epoch {i}: ')\n",
    "            #     print(np.abs(clf.weights).sum(), np.abs(clf.weights).max(), np.abs(clf.weights).min()) # print min max sum of absolute value of weights per epoch\n",
    "            # print absolute value of weight updates\n",
    "            # okay try eta / 10, eta / 100\n",
    "        break\n",
    "        \n",
    "    print(f'best epoch: {best_epoch}')\n",
    "    print(f'last train accuracy: {train_accuracy}')\n",
    "    print(f'best tune accuracy: {best_accuracy}')\n",
    "    return best_epoch\n",
    "\n",
    "def cv(num_folds=10):\n",
    "    cv_results = []\n",
    "    ks = []\n",
    "    for test_fold in range(num_folds):\n",
    "        print(f'starting fold {test_fold}')\n",
    "        start = time.time()\n",
    "        X_test, y_test, example_names_test = load_folds([test_fold])\n",
    "        train_folds = [fold for fold in range(num_folds) if fold != test_fold]\n",
    "        best_epoch = get_tune_results(train_folds)\n",
    "        X_train, y_train, example_names_train = load_folds(train_folds)\n",
    "        clf = Perceptron(X_train.shape[1], step_function)\n",
    "        for i in range(int(best_epoch * (8/9))):\n",
    "            perm = np.random.permutation(X_train.shape[0])\n",
    "            X_train = X_train[perm]\n",
    "            y_train = y_train[perm]\n",
    "            X_batched, y_batched = create_batched_data(X_train, y_train, batch_size=4)\n",
    "            clf.fit(X_batched, y_batched)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        cv_results.append(acc)\n",
    "        end = time.time()\n",
    "        print(f'time for fold: {end - start}')\n",
    "        # break\n",
    "\n",
    "    print(ks)\n",
    "    return cv_results\n",
    "\n",
    "cv_scores = cv()\n",
    "print(f'average cv score: {np.mean(cv_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min cv score: 0.6551724137931034\n",
      "max cv score: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(f'min cv score: {np.min(cv_scores)}')\n",
    "print(f'max cv score: {np.max(cv_scores)}')\n",
    "\n",
    "# before bugfix\n",
    "# min cv score: 0.6551724137931034\n",
    "# max cv score: 0.9333333333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min cv score: 0.3793103448275862\n",
      "max cv score: 0.8620689655172413\n"
     ]
    }
   ],
   "source": [
    "print(f'min cv score: {np.min(cv_scores)}')\n",
    "print(f'max cv score: {np.max(cv_scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3b\n",
    "\n",
    "1. Repeat above but use one layer of 128 ReLU hidden units & backprop\n",
    "2. Use Sigmoid as the activation function for the output\n",
    "3. If maxEpochs = 10,000 runs too slowly, use 5,000 or 1,000\n",
    "4. Optional: try #HUs in {16, 32, 64, 128, 256, 512, 1024, …, YouChooseMax} and use the best #HUs + stopping epoch on tune set per train-test fold\n",
    "5. Compare to results discussed in HW3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23413753346060412"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, eta=0.01):\n",
    "        kaiming_std = np.sqrt(2/13) # kaiming initialization\n",
    "        self.hidden_weights = np.random.normal(0, kaiming_std, size=(128, 13))\n",
    "        self.hidden_bias = np.random.normal(0, kaiming_std, size=128)\n",
    "        self.output_weights = np.random.normal(0, kaiming_std, size=128)\n",
    "        self.output_bias = np.random.normal(0, kaiming_std)\n",
    "        self.backprop_state = {}\n",
    "        self.eta = eta\n",
    "\n",
    "    def relu(self, x): # vectorized function\n",
    "        return np.maximum(x, 0) \n",
    "\n",
    "    def sigmoid(self, x): # vectorized function\n",
    "        return 1 / (1 + np.exp(-x)) \n",
    "\n",
    "    def fit(self, X: np.array, y: np.array): # X is 3-d array, y is 2-d array with batch size in first dimension\n",
    "        for X_batch, y_batch in zip(X, y):\n",
    "            # print(f'weights before: {self.weights}')\n",
    "            total_hidden_update = np.zeros((128, 13))\n",
    "            total_output_update = np.zeros(128)\n",
    "            total_hidden_bias_update = np.zeros(128)\n",
    "            total_output_bias_update = 0\n",
    "\n",
    "            assert X_batch.shape[0] == y_batch.shape[0]\n",
    "            for example, y in zip(X_batch, y_batch):\n",
    "                y_bar = self.forward_prop(example)\n",
    "                hidden_update, output_update, hidden_error, output_error = self.back_prop(example, y)\n",
    "                total_hidden_update += hidden_update\n",
    "                total_output_update += output_update\n",
    "                total_hidden_bias_update += hidden_error\n",
    "                total_output_bias_update += output_error\n",
    "\n",
    "            self.hidden_weights -= total_hidden_update / X_batch.shape[0]\n",
    "            self.output_weights -= total_output_update / X_batch.shape[0]\n",
    "            self.hidden_bias -= total_hidden_bias_update / X_batch.shape[0]\n",
    "            self.output_bias -= total_output_bias_update / X_batch.shape[0]\n",
    "            # print(f'weights after: {self.weights}')\n",
    "\n",
    "    def back_prop(self, x, y):\n",
    "        output_error = (self.backprop_state['a_L'] - y)*(1 - self.backprop_state['a_L'])*self.backprop_state['a_L']\n",
    "        output_update = self.backprop_state['a_L-1'] * output_error\n",
    "\n",
    "        hidden_error = output_error * self.output_weights * self.backprop_state['sigprime(z_L-1)']\n",
    "        broadcasted_example = np.broadcast_to(x, (128, 13))\n",
    "        hidden_update = np.broadcast_to(hidden_error, (13, 128)).T # * broadcasted_example\n",
    "\n",
    "        return hidden_update, output_update, hidden_error, output_error\n",
    "\n",
    "\n",
    "    def forward_prop(self, x):\n",
    "        x = self.hidden_weights @ x + self.hidden_bias\n",
    "        self.backprop_state['z_L-1'] = x\n",
    "        self.backprop_state['sigprime(z_L-1)'] = np.where(x > 0, 1, 0)\n",
    "        x = self.relu(x)\n",
    "        self.backprop_state['a_L-1'] = x\n",
    "        x = self.output_weights @ x + self.output_bias\n",
    "        self.backprop_state['z_L'] = x\n",
    "        x = self.sigmoid(x)\n",
    "        self.backprop_state['a_L'] = x\n",
    "\n",
    "        # print(self.backprop_state)\n",
    "        return x \n",
    "\n",
    "\n",
    "    def predict(self, examples: np.array):\n",
    "        output = []\n",
    "        for example in examples:\n",
    "            output.append(self.forward_prop(example))\n",
    "        return np.array(output)\n",
    "\n",
    "\n",
    "clf = NeuralNetwork()\n",
    "clf.forward_prop(np.ones(13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [1.6872583e-06]\n",
      "100: [1.68725827e-06]\n",
      "200: [1.68725824e-06]\n",
      "300: [1.68725821e-06]\n",
      "400: [1.68725817e-06]\n",
      "500: [1.68725814e-06]\n",
      "600: [1.68725811e-06]\n",
      "700: [1.68725808e-06]\n",
      "800: [1.68725804e-06]\n",
      "900: [1.68725801e-06]\n"
     ]
    }
   ],
   "source": [
    "# fit to random vector\n",
    "\n",
    "x = np.random.normal(size=(1, 1, 13))\n",
    "y = np.ones((1, 1))\n",
    "for i in range(1000):\n",
    "    clf.fit(x, y)\n",
    "    if (i % 100) == 0:\n",
    "        print(f'{i}: {y[0] - clf.forward_prop(x[0][0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X: np.array, means=None, std=None):\n",
    "    if means is None or std is None:\n",
    "        means = X.mean(axis=0)\n",
    "        std = X.std(axis=0)\n",
    "\n",
    "    return (X - means) / std, means, std\n",
    "\n",
    "\n",
    "def min_max_normalize(X: np.array):\n",
    "    return (X - X.min()) / (X.max() - X.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.263676837555066, -2.8574475022613934)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try on 1 fold\n",
    "\n",
    "X_train, y_train, _ = load_folds([0])\n",
    "X_train, means, std = normalize(X_train)\n",
    "# X_train = min_max_normalize(X_train)\n",
    "\n",
    "X_train.max(), X_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 4, 13)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batched, y_batched = create_batched_data(X_train, y_train, batch_size=4)\n",
    "X_batched.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 164/1000 [00:00<00:01, 820.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.6\n",
      "100: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 330/1000 [00:00<00:00, 808.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200: 0.9666666666666667\n",
      "300: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 491/1000 [00:00<00:00, 788.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400: 0.9666666666666667\n",
      "500: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 731/1000 [00:00<00:00, 789.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600: 0.9666666666666667\n",
      "700: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 893/1000 [00:01<00:00, 799.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800: 0.9666666666666667\n",
      "900: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 797.33it/s]\n"
     ]
    }
   ],
   "source": [
    "clf = NeuralNetwork()\n",
    "best_epoch = 0\n",
    "best_accuracy = 0\n",
    "for i in trange(1000):\n",
    "    # print(X_batched.shape)\n",
    "    clf.fit(X_batched, y_batched)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_train = np.round(y_pred_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    if i % 100 == 0:\n",
    "        # print(y_pred_train)\n",
    "        print(f'{i}: {train_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fold 0\n",
      "Xtune: (30, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 441/1000 [00:04<00:06, 89.42it/s]/var/folders/lr/597pxhmx2z78r4vysc_dvsth0000gn/T/ipykernel_82293/481716268.py:18: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "100%|██████████| 1000/1000 [00:11<00:00, 89.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 13\n",
      "last train accuracy: 0.9026217228464419\n",
      "best tune accuracy: 0.8666666666666667\n",
      "test acc 0: 0.8\n",
      "time for fold: 11.326462030410767\n",
      "starting fold 1\n",
      "Xtune: (30, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 100.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 16\n",
      "last train accuracy: 0.9367088607594937\n",
      "best tune accuracy: 0.8333333333333334\n",
      "test acc 1: 0.8333333333333334\n",
      "time for fold: 10.106119871139526\n",
      "starting fold 2\n",
      "Xtune: (30, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 100.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 94\n",
      "last train accuracy: 0.890295358649789\n",
      "best tune accuracy: 0.8333333333333334\n",
      "test acc 2: 0.8666666666666667\n",
      "time for fold: 10.644702911376953\n",
      "starting fold 3\n",
      "Xtune: (30, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 100.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 554\n",
      "last train accuracy: 0.9071729957805907\n",
      "best tune accuracy: 0.8\n",
      "test acc 3: 0.7\n",
      "time for fold: 13.874933958053589\n",
      "starting fold 4\n",
      "Xtune: (30, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 100.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 0\n",
      "last train accuracy: 0.9113924050632911\n",
      "best tune accuracy: 0.8\n",
      "test acc 4: 0.43333333333333335\n",
      "time for fold: 9.975451946258545\n",
      "starting fold 5\n",
      "Xtune: (30, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 100.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 257\n",
      "last train accuracy: 0.9282700421940928\n",
      "best tune accuracy: 0.8\n",
      "test acc 5: 0.8333333333333334\n",
      "time for fold: 11.763781785964966\n",
      "starting fold 6\n",
      "Xtune: (30, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 100.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 3\n",
      "last train accuracy: 0.9493670886075949\n",
      "best tune accuracy: 0.8\n",
      "test acc 6: 0.6333333333333333\n",
      "time for fold: 9.990205764770508\n",
      "starting fold 7\n",
      "Xtune: (30, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 100.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 188\n",
      "last train accuracy: 0.9159663865546218\n",
      "best tune accuracy: 0.8666666666666667\n",
      "test acc 7: 0.7586206896551724\n",
      "time for fold: 11.327388048171997\n",
      "starting fold 8\n",
      "Xtune: (30, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 100.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 18\n",
      "last train accuracy: 0.9453781512605042\n",
      "best tune accuracy: 0.8333333333333334\n",
      "test acc 8: 0.9310344827586207\n",
      "time for fold: 10.105164051055908\n",
      "starting fold 9\n",
      "Xtune: (30, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 100.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 3\n",
      "last train accuracy: 0.9201680672268907\n",
      "best tune accuracy: 0.8333333333333334\n",
      "test acc 9: 0.7241379310344828\n",
      "time for fold: 9.974010229110718\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8,\n",
       " 0.8333333333333334,\n",
       " 0.8666666666666667,\n",
       " 0.7,\n",
       " 0.43333333333333335,\n",
       " 0.8333333333333334,\n",
       " 0.6333333333333333,\n",
       " 0.7586206896551724,\n",
       " 0.9310344827586207,\n",
       " 0.7241379310344828]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def get_tune_results(train_tune_folds: List[int], batch_size=4, MAX_EPOCHS=1000): # TODO: set batch size 1 for debugging \n",
    "    for tune_fold in range(len(train_tune_folds)):\n",
    "        X_tune, y_tune, example_names_tune = load_folds([tune_fold])\n",
    "        train_folds = [fold for fold in train_tune_folds if fold != tune_fold]\n",
    "        X_train, y_train, example_names_train = load_folds(train_folds)\n",
    "\n",
    "        X_train, means, std = normalize(X_train)\n",
    "        X_tune, _, _ = normalize(X_tune, means=means, std=std)\n",
    "\n",
    "        print(f'Xtune: {X_tune.shape}')\n",
    "\n",
    "        clf = NeuralNetwork()\n",
    "        best_epoch = 0\n",
    "        best_accuracy = 0\n",
    "        for i in trange(MAX_EPOCHS):\n",
    "            perm = np.random.permutation(X_train.shape[0])\n",
    "            X_train = X_train[perm]\n",
    "            y_train = y_train[perm]\n",
    "            X_batched, y_batched = create_batched_data(X_train, y_train, batch_size=batch_size)\n",
    "            # print(X_batched.shape)\n",
    "            clf.fit(X_batched, y_batched)\n",
    "            y_pred_train = clf.predict(X_train)\n",
    "            y_pred_train = np.round(y_pred_train)\n",
    "            train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "            if train_accuracy == 1:\n",
    "                print(f\"achieved perfect train accuracy at epoch {i}\")\n",
    "                break\n",
    "            y_pred = clf.predict(X_tune)\n",
    "            y_pred = np.round(y_pred)\n",
    "            tune_accuracy = accuracy_score(y_tune, y_pred)\n",
    "            if tune_accuracy > best_accuracy:\n",
    "                best_epoch = i\n",
    "                best_accuracy = tune_accuracy\n",
    "                # print(best_accuracy, best_epoch)\n",
    "            # if i % 1000 == 0:\n",
    "            #     print(f'epoch {i}: ')\n",
    "            #     print(np.abs(clf.weights).sum(), np.abs(clf.weights).max(), np.abs(clf.weights).min()) # print min max sum of absolute value of weights per epoch\n",
    "            # print absolute value of weight updates\n",
    "            # okay try eta / 10, eta / 100\n",
    "        break\n",
    "        \n",
    "    print(f'best epoch: {best_epoch}')\n",
    "    print(f'last train accuracy: {train_accuracy}')\n",
    "    print(f'best tune accuracy: {best_accuracy}')\n",
    "    return best_epoch\n",
    "\n",
    "def cv(num_folds=10):\n",
    "    cv_results = []\n",
    "    ks = []\n",
    "    for test_fold in range(num_folds):\n",
    "        print(f'starting fold {test_fold}')\n",
    "        start = time.time()\n",
    "        X_test, y_test, example_names_test = load_folds([test_fold])\n",
    "        train_folds = [fold for fold in range(num_folds) if fold != test_fold]\n",
    "        best_epoch = get_tune_results(train_folds)\n",
    "        X_train, y_train, example_names_train = load_folds(train_folds)\n",
    "\n",
    "        X_train, means, std = normalize(X_train)\n",
    "        X_test, _, _ = normalize(X_test, means=means, std=std)\n",
    "        clf = NeuralNetwork()\n",
    "        for i in range(int(best_epoch * (8/9))):\n",
    "            perm = np.random.permutation(X_train.shape[0])\n",
    "            X_train = X_train[perm]\n",
    "            y_train = y_train[perm]\n",
    "            X_batched, y_batched = create_batched_data(X_train, y_train, batch_size=4)\n",
    "            clf.fit(X_batched, y_batched)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_pred = np.round(y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f'test acc {test_fold}: {acc}')\n",
    "        cv_results.append(acc)\n",
    "        end = time.time()\n",
    "        print(f'time for fold: {end - start}')\n",
    "        # break\n",
    "\n",
    "    print(ks)\n",
    "    return cv_results\n",
    "\n",
    "\n",
    "\n",
    "cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7513793103448276"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.8,\n",
    " 0.8333333333333334,\n",
    " 0.8666666666666667,\n",
    " 0.7,\n",
    " 0.43333333333333335,\n",
    " 0.8333333333333334,\n",
    " 0.6333333333333333,\n",
    " 0.7586206896551724,\n",
    " 0.9310344827586207,\n",
    " 0.7241379310344828])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebf4d58f2b06e9f21676e768ca6276364ab43d26f7d392ff17c91d23028c0e8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
