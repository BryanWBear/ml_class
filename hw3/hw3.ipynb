{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 3a: Implement Perceptron for Heart Disease\n",
    "\n",
    "1. Use step function and $\\eta = 0.1$ and batch size = 4 (ok to use 1 if need be)\n",
    "2. Use TUNE set to choose ‘early stopping’ epoch for each of 10 test folds (maxEpochs = 10,000 but can stop if / when all trainset examples correct)\n",
    "3. Ok to just use ONE tune set (but feel free to use 9 as done in HW1 and HW2)\n",
    "4. Once epochsToUse estimated, train on all 9 folds; use (8/9) epochsToUse\n",
    "5. Report best epoch and min, mean, and max accuracy per train-tune fold \n",
    "6. Compare to Random Forests and kNN test set min, mean, and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def step_function(x: int):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, num_weights, activation_function, learning_rate=0.1):\n",
    "        self.weights = np.zeros(num_weights + 1)\n",
    "        self.activation_function = activation_function\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def fit(self, X: np.array, y: np.array): # X is 3-d array, y is 2-d array with batch size in first dimension\n",
    "        updates = []\n",
    "        for X_batch, y_batch in zip(X, y):\n",
    "            assert X_batch.shape[0] == y_batch.shape[0]\n",
    "            y_pred_batch = []\n",
    "            for example, y in zip(X_batch, y_batch):\n",
    "                print(example)\n",
    "                example = np.append(example, 1)\n",
    "                y_bar = self.predict(example)\n",
    "                update = self.learning_rate * (y - y_bar) * example\n",
    "            update = self.learning_rate * (X_batch.T * (y_batch - y_pred_batch)).T\n",
    "            updates.append(update)\n",
    "\n",
    "        print(update)\n",
    "        self.weights = self.weights + np.sum(update(axis=1))\n",
    "\n",
    "    def predict(self, example: np.array):\n",
    "        return self.activation_function(self.weights.T @ example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (np.ones((3, 4)).T * np.array([1, 0, 1])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 1]\n",
      "[2 3 4 1]\n",
      "[2 3 4 1]\n",
      "[5 6 7 1]\n",
      "[ 8  9 10  1]\n",
      "[2 3 4 1]\n",
      "[[-0.5 -0.6 -0.7 -0.1]\n",
      " [-0.8 -0.9 -1.  -0.1]\n",
      " [ 0.   0.   0.   0. ]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-6279e31b0027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-61-399e20984788>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "# unit tests\n",
    "\n",
    "clf = Perceptron(4, step_function)\n",
    "x = np.array([[[1, 2, 3, 1], [2, 3, 4, 1], [2, 3, 4, 1]], [[5, 6, 7, 1], [8, 9, 10, 1], [2, 3, 4, 1]]])\n",
    "y = np.array([[1, 0, 1], [0, 0, 1]])\n",
    "\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3b\n",
    "\n",
    "1. Repeat above but use one layer of 128 ReLU hidden units & backprop\n",
    "2. Use Sigmoid as the activation function for the output\n",
    "3. If maxEpochs = 10,000 runs too slowly, use 5,000 or 1,000\n",
    "4. Optional: try #HUs in {16, 32, 64, 128, 256, 512, 1024, …, YouChooseMax} and use the best #HUs + stopping epoch on tune set per train-test fold\n",
    "5. Compare to results discussed in HW3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d20419c564893ff7827d87520a6c3b654e0969c6aa9ae3b46a277348f487f0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
